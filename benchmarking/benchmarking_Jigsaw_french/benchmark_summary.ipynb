{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a203dcb",
   "metadata": {},
   "source": [
    "# Summary of the benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e30488",
   "metadata": {},
   "source": [
    "The results can be compared with [this article](https://arxiv.org/pdf/2403.08035) in which GPT-3.5 achieves $\\text{acc}=0.89$ and $F_1=0.93$ in *English Hate Speech Detection*. We use newer models in this benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb68075",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "Our task is a binary classification. We aim at reaching a ground truth $f:E\\to\\{0,1\\}$ which we will estimate with $\\hat f:E\\to\\{0,1\\}$.\n",
    "\n",
    "### Confusion Matrix Notations (Binary Classification)\n",
    "\n",
    "|              | Predicted 0 | Predicted 1 |\n",
    "| ------------ | ----------- | ----------- |\n",
    "| **Actual 0** | TN          | FP          |\n",
    "| **Actual 1** | FN          | TP          |\n",
    "\n",
    "* **TP** = True Positives (predicted 1, actual 1)\n",
    "* **TN** = True Negatives (predicted 0, actual 0)\n",
    "* **FP** = False Positives (predicted 1, actual 0)\n",
    "* **FN** = False Negatives (predicted 0, actual 1)\n",
    "\n",
    "### Metrics \n",
    "\n",
    "- **Precision\\_0** : The proportion of predicted class 0 that is actually class 0 : $$\\text{Precision}\\_0 = \\frac{\\text{TN}}{\\text{TN} + \\text{FN}}$$\n",
    "- **Recall\\_0** : The proportion of actual class 0 correctly predicted as class 0 : $$\\text{Recall}\\_0 = \\frac{\\text{TN}}{\\text{TN} + \\text{FP}}$$\n",
    "- **F1\\_0** : The harmonic mean of Precision\\_0 and Recall\\_0 : $$\\text{F1}_0 = 2 \\cdot \\frac{\\text{Precision}\\_0 \\times \\text{Recall}\\_0}{\\text{Precision}\\_0 + \\text{Recall}\\_0}$$\n",
    "- **Precision\\_1** : The proportion of predicted class 1 that is actually class 1 : $$\\text{Precision}\\_1 = \\frac{\\text{TN}}{\\text{TN} + \\text{FN}}$$\n",
    "- **Recall\\_1** : The proportion of actual class 1 correctly predicted as class 1 : $$\\text{Recall}\\_1 = \\frac{\\text{TN}}{\\text{TN} + \\text{FP}}$$\n",
    "- **F1\\_1** : The harmonic mean of Precision\\_1 and Recall\\_1 : $$\\text{F1}_0 = 2 \\cdot \\frac{\\text{Precision}\\_1 \\times \\text{Recall}\\_1}{\\text{Precision}\\_1 + \\text{Recall}\\_1}$$\n",
    "- **Accuracy** : The proportion of all correct predictions : $$\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}$$\n",
    "- **ROC AUC** : Area under the **Receiver Operating Characteristic** curve. It evaluates the tradeoff between True Positive Rate (TPR) and False Positive Rate (FPR) over all thresholds : $$\\text{TPR (Recall)} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}, \\quad \n",
    "\\text{FPR} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fce313",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "407caa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "import os\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.panel import Panel\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1736e7f7",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed44c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path('../..')\n",
    "DATA_PATH = ROOT / \"data\"\n",
    "BENCHMARK_PATH = DATA_PATH / \"benchmark_jigsaw\"\n",
    "\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc73b774",
   "metadata": {},
   "source": [
    "## Load predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cffbb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_exclude = [\n",
    "    \"benchmark_jigsaw.csv\",\n",
    "    \"checkpoint\",\n",
    "    \"eng\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8744c715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loaded benchmark with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">396</span> entries.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loaded benchmark with \u001b[1;36m396\u001b[0m entries.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_benchmark = pd.read_csv(BENCHMARK_PATH / \"benchmark_jigsaw.csv\", encoding = 'utf-8')\n",
    "len_benchmark = len(df_benchmark)\n",
    "console.print(f\"Loaded benchmark with {len_benchmark} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79787c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e6865c831da40459</td>\n",
       "      <td>Combining 'Official requests for clemency' sec...</td>\n",
       "      <td>Combiner la section 'Demandes officielles de c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cff2b456e5059b47</td>\n",
       "      <td>Web \\n\\nIs this her own website? 113.22.84.65</td>\n",
       "      <td>Web\\n\\nEst-ce son propre site web ? 113.22.84.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>880d3d608f37bee3</td>\n",
       "      <td>RFCU \\n\\nFYI, I have opened Wikipedia:Requests...</td>\n",
       "      <td>RFCU \\n\\nPour info, j'ai ouvert Wikipedia:Requ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd29d52a4320a2e4</td>\n",
       "      <td>Monitor for cleanup: \\nAs of the date signed b...</td>\n",
       "      <td>Surveillance pour nettoyage :  \\nÀ la date sig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d70e773c975839e1</td>\n",
       "      <td>I concur and have done so.</td>\n",
       "      <td>Je suis d'accord et je l'ai fait.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>bf5aae5b17fb0b77</td>\n",
       "      <td>because I am a huge faggot</td>\n",
       "      <td>parce que je suis un énorme pédé</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>8947f2c12aea0a32</td>\n",
       "      <td>If no-one beats me to it, I'll knock something...</td>\n",
       "      <td>Si personne ne me devance, je vais bricoler qu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>ccf05c5d4b791836</td>\n",
       "      <td>ur a faggot, fuck off and get a real job and s...</td>\n",
       "      <td>T'es un pédé, casse-toi et trouve un vrai boul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>ae7a53526025c0e2</td>\n",
       "      <td>I SAID SHUT UP, YOU STUPID, STUPID...</td>\n",
       "      <td>J'AI DIT FERME TA GUEULE, ESPÈCE DE BÊTE, BÊTE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>c253e034605ee865</td>\n",
       "      <td>is true. so i want to express that grant is ga...</td>\n",
       "      <td>C'est vrai. Donc je veux dire que Grant est pé...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>396 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               msg_id                                      original_text  \\\n",
       "0    e6865c831da40459  Combining 'Official requests for clemency' sec...   \n",
       "1    cff2b456e5059b47      Web \\n\\nIs this her own website? 113.22.84.65   \n",
       "2    880d3d608f37bee3  RFCU \\n\\nFYI, I have opened Wikipedia:Requests...   \n",
       "3    dd29d52a4320a2e4  Monitor for cleanup: \\nAs of the date signed b...   \n",
       "4    d70e773c975839e1                         I concur and have done so.   \n",
       "..                ...                                                ...   \n",
       "391  bf5aae5b17fb0b77                         because I am a huge faggot   \n",
       "392  8947f2c12aea0a32  If no-one beats me to it, I'll knock something...   \n",
       "393  ccf05c5d4b791836  ur a faggot, fuck off and get a real job and s...   \n",
       "394  ae7a53526025c0e2              I SAID SHUT UP, YOU STUPID, STUPID...   \n",
       "395  c253e034605ee865  is true. so i want to express that grant is ga...   \n",
       "\n",
       "                                               content  label  \n",
       "0    Combiner la section 'Demandes officielles de c...      0  \n",
       "1     Web\\n\\nEst-ce son propre site web ? 113.22.84.65      0  \n",
       "2    RFCU \\n\\nPour info, j'ai ouvert Wikipedia:Requ...      0  \n",
       "3    Surveillance pour nettoyage :  \\nÀ la date sig...      0  \n",
       "4                    Je suis d'accord et je l'ai fait.      0  \n",
       "..                                                 ...    ...  \n",
       "391                   parce que je suis un énorme pédé      1  \n",
       "392  Si personne ne me devance, je vais bricoler qu...      1  \n",
       "393  T'es un pédé, casse-toi et trouve un vrai boul...      1  \n",
       "394  J'AI DIT FERME TA GUEULE, ESPÈCE DE BÊTE, BÊTE...      1  \n",
       "395  C'est vrai. Donc je veux dire que Grant est pé...      1  \n",
       "\n",
       "[396 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c8024b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span> additional files from benchmark directory.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loaded \u001b[1;36m22\u001b[0m additional files from benchmark directory.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for file in os.listdir(BENCHMARK_PATH):\n",
    "    if file.endswith('.csv') and all(file_exclude not in file for file_exclude in to_exclude):\n",
    "        file_path = BENCHMARK_PATH / file\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        df['file'] = file  \n",
    "        assert len(df) == len_benchmark, f\"Length mismatch for {file}: {len(df)} vs {len_benchmark}\"\n",
    "        assert \"prediction\" in df.columns, f\"'prediction' column missing in {file}\"\n",
    "        assert \"label\" in df.columns, f\"'prediction' column missing in {file}\"\n",
    "        dfs.append(df)\n",
    "\n",
    "console.print(f\"Loaded {len(dfs)} additional files from benchmark directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a088d5",
   "metadata": {},
   "source": [
    "## Compute the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a8630eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for df in dfs:\n",
    "    file_name = df['file'].iloc[0]\n",
    "    y_true = df['label'].astype(int)\n",
    "    y_pred = df['prediction'].apply(lambda x: 1 if x else 0).astype(int)\n",
    "    row = {\"Model\": file_name.replace('.csv', '').replace('_', ' ')}\n",
    "\n",
    "    try:\n",
    "        report = classification_report(y_true, y_pred, output_dict=True)\n",
    "        row.update({\n",
    "            \"Precision_0\": report['0']['precision'],\n",
    "            \"Recall_0\": report['0']['recall'],\n",
    "            \"F1_0\": report['0']['f1-score'],\n",
    "            \"Precision_1\": report['1']['precision'],\n",
    "            \"Recall_1\": report['1']['recall'],\n",
    "            \"F1_1\": report['1']['f1-score'],\n",
    "            \"Accuracy\": report['accuracy'],\n",
    "        })\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]Error computing classification report for {file_name}: {e}[/red]\")\n",
    "\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_true, y_pred)\n",
    "        row[\"ROC_AUC\"] = roc_auc\n",
    "    except:\n",
    "        row[\"ROC_AUC\"] = None\n",
    "\n",
    "    results.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab93c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                         Benchmark Summary for All Models                                          </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">          Model           </span>┃<span style=\"font-weight: bold\"> Precision_0 </span>┃<span style=\"font-weight: bold\"> Recall_0 </span>┃<span style=\"font-weight: bold\"> F1_0  </span>┃<span style=\"font-weight: bold\"> Precision_1 </span>┃<span style=\"font-weight: bold\"> Recall_1 </span>┃<span style=\"font-weight: bold\"> F1_1  </span>┃<span style=\"font-weight: bold\"> Accuracy </span>┃<span style=\"font-weight: bold\"> ROC_AUC </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━┩\n",
       "│   Qwen-2.5-3B-Instruct   │    0.931    │  0.960   │ 0.945 │    0.958    │  0.929   │ 0.944 │  0.944   │  0.944  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│    gpt-4o-mini simple    │    0.944    │  0.929   │ 0.936 │    0.930    │  0.944   │ 0.937 │  0.937   │  0.937  │\n",
       "│          prompt          │             │          │       │             │          │       │          │         │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│       gpt-4o-mini        │    0.917    │  0.949   │ 0.933 │    0.948    │  0.914   │ 0.931 │  0.932   │  0.932  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│    perspective scores    │    0.882    │  0.980   │ 0.928 │    0.977    │  0.869   │ 0.920 │  0.924   │  0.924  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│         o4-mini          │    0.937    │  0.904   │ 0.920 │    0.907    │  0.939   │ 0.923 │  0.922   │  0.922  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│ gemini-2.0-flash simple  │    0.956    │  0.884   │ 0.919 │    0.892    │  0.960   │ 0.925 │  0.922   │  0.922  │\n",
       "│          prompt          │             │          │       │             │          │       │          │         │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│     gemini-2.0-flash     │    0.915    │  0.924   │ 0.920 │    0.923    │  0.914   │ 0.919 │  0.919   │  0.919  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│       shieldgemma        │    0.932    │  0.899   │ 0.915 │    0.902    │  0.934   │ 0.918 │  0.917   │  0.917  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│      gemini-1.5-pro      │    0.910    │  0.924   │ 0.917 │    0.923    │  0.909   │ 0.916 │  0.917   │  0.917  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│      deepseek-chat       │    0.937    │  0.894   │ 0.915 │    0.899    │  0.939   │ 0.919 │  0.917   │  0.917  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│   Qwen-2.5-7B-Instruct   │    0.937    │  0.894   │ 0.915 │    0.899    │  0.939   │ 0.919 │  0.917   │  0.917  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│      mistral medium      │    0.889    │  0.934   │ 0.911 │    0.931    │  0.884   │ 0.907 │  0.909   │  0.909  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│          gpt-4o          │    0.931    │  0.884   │ 0.907 │    0.889    │  0.934   │ 0.911 │  0.909   │  0.909  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│  openai omni moderation  │    0.901    │  0.919   │ 0.910 │    0.918    │  0.899   │ 0.908 │  0.909   │  0.909  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│   google-gemma-2-2b-it   │    0.944    │  0.854   │ 0.897 │    0.866    │  0.949   │ 0.906 │  0.902   │  0.902  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│        Qwen-3-4B         │    0.859    │  0.955   │ 0.904 │    0.949    │  0.843   │ 0.893 │  0.899   │  0.899  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│    mistral moderation    │    0.856    │  0.960   │ 0.905 │    0.954    │  0.838   │ 0.892 │  0.899   │  0.899  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│   Mistral-7B-Instruct    │    0.885    │  0.894   │ 0.889 │    0.893    │  0.884   │ 0.888 │  0.889   │  0.889  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│       Qwen-3-1.7B        │    0.775    │  0.975   │ 0.864 │    0.966    │  0.717   │ 0.823 │  0.846   │  0.846  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│        polyguard         │    0.743    │  0.980   │ 0.845 │    0.970    │  0.662   │ 0.787 │  0.821   │  0.821  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│  Qwen-2.5-1.5B-Instruct  │    0.981    │  0.515   │ 0.675 │    0.671    │  0.990   │ 0.800 │  0.753   │  0.753  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│        llamaguard        │    0.580    │  0.990   │ 0.731 │    0.966    │  0.283   │ 0.438 │  0.636   │  0.636  │\n",
       "└──────────────────────────┴─────────────┴──────────┴───────┴─────────────┴──────────┴───────┴──────────┴─────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                         Benchmark Summary for All Models                                          \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         Model          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPrecision_0\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mRecall_0\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mF1_0 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPrecision_1\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mRecall_1\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mF1_1 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mAccuracy\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mROC_AUC\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━┩\n",
       "│   Qwen-2.5-3B-Instruct   │    0.931    │  0.960   │ 0.945 │    0.958    │  0.929   │ 0.944 │  0.944   │  0.944  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│    gpt-4o-mini simple    │    0.944    │  0.929   │ 0.936 │    0.930    │  0.944   │ 0.937 │  0.937   │  0.937  │\n",
       "│          prompt          │             │          │       │             │          │       │          │         │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│       gpt-4o-mini        │    0.917    │  0.949   │ 0.933 │    0.948    │  0.914   │ 0.931 │  0.932   │  0.932  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│    perspective scores    │    0.882    │  0.980   │ 0.928 │    0.977    │  0.869   │ 0.920 │  0.924   │  0.924  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│         o4-mini          │    0.937    │  0.904   │ 0.920 │    0.907    │  0.939   │ 0.923 │  0.922   │  0.922  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│ gemini-2.0-flash simple  │    0.956    │  0.884   │ 0.919 │    0.892    │  0.960   │ 0.925 │  0.922   │  0.922  │\n",
       "│          prompt          │             │          │       │             │          │       │          │         │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│     gemini-2.0-flash     │    0.915    │  0.924   │ 0.920 │    0.923    │  0.914   │ 0.919 │  0.919   │  0.919  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│       shieldgemma        │    0.932    │  0.899   │ 0.915 │    0.902    │  0.934   │ 0.918 │  0.917   │  0.917  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│      gemini-1.5-pro      │    0.910    │  0.924   │ 0.917 │    0.923    │  0.909   │ 0.916 │  0.917   │  0.917  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│      deepseek-chat       │    0.937    │  0.894   │ 0.915 │    0.899    │  0.939   │ 0.919 │  0.917   │  0.917  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│   Qwen-2.5-7B-Instruct   │    0.937    │  0.894   │ 0.915 │    0.899    │  0.939   │ 0.919 │  0.917   │  0.917  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│      mistral medium      │    0.889    │  0.934   │ 0.911 │    0.931    │  0.884   │ 0.907 │  0.909   │  0.909  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│          gpt-4o          │    0.931    │  0.884   │ 0.907 │    0.889    │  0.934   │ 0.911 │  0.909   │  0.909  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│  openai omni moderation  │    0.901    │  0.919   │ 0.910 │    0.918    │  0.899   │ 0.908 │  0.909   │  0.909  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│   google-gemma-2-2b-it   │    0.944    │  0.854   │ 0.897 │    0.866    │  0.949   │ 0.906 │  0.902   │  0.902  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│        Qwen-3-4B         │    0.859    │  0.955   │ 0.904 │    0.949    │  0.843   │ 0.893 │  0.899   │  0.899  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│    mistral moderation    │    0.856    │  0.960   │ 0.905 │    0.954    │  0.838   │ 0.892 │  0.899   │  0.899  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│   Mistral-7B-Instruct    │    0.885    │  0.894   │ 0.889 │    0.893    │  0.884   │ 0.888 │  0.889   │  0.889  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│       Qwen-3-1.7B        │    0.775    │  0.975   │ 0.864 │    0.966    │  0.717   │ 0.823 │  0.846   │  0.846  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│        polyguard         │    0.743    │  0.980   │ 0.845 │    0.970    │  0.662   │ 0.787 │  0.821   │  0.821  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│  Qwen-2.5-1.5B-Instruct  │    0.981    │  0.515   │ 0.675 │    0.671    │  0.990   │ 0.800 │  0.753   │  0.753  │\n",
       "├──────────────────────────┼─────────────┼──────────┼───────┼─────────────┼──────────┼───────┼──────────┼─────────┤\n",
       "│        llamaguard        │    0.580    │  0.990   │ 0.731 │    0.966    │  0.283   │ 0.438 │  0.636   │  0.636  │\n",
       "└──────────────────────────┴─────────────┴──────────┴───────┴─────────────┴──────────┴───────┴──────────┴─────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Convert to DataFrame & Display as Rich Table ===\n",
    "summary_df = pd.DataFrame(results)\n",
    "summary_df = summary_df.sort_values(by=\"Accuracy\", ascending=False) \n",
    "\n",
    "# === Print Table in Rich ===\n",
    "rich_table = Table(title=\"Benchmark Summary for All Models\", show_lines=True)\n",
    "for col in summary_df.columns:\n",
    "    rich_table.add_column(col, justify=\"center\")\n",
    "\n",
    "for _, row in summary_df.iterrows():\n",
    "    rich_table.add_row(*[f\"{x:.3f}\" if isinstance(x, float) else str(x) for x in row])\n",
    "\n",
    "console.print(rich_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SJTU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
